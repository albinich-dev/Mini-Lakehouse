# Mini-Lakehouse. Архитектура проекта
##1. Цель проекта
Создать универсальное ядро для обработки и трансформации данных, реализованное в архитектуре Lakehouse. Решение предназначено для построения воспроизводимых, расширяемых и масштабируемых пайплайнов, охватывающих весь цикл работы с данными: от получения из внешних источников до подготовки аналитических витрин. Такая структура обеспечивает гибкость для задач аналитики, отчётности и интеграции с downstream-системами.

## 2. Архитектурные принципы

- **Разделение ответственности**: каждый слой отвечает за определённый этап обработки — от хранения необработанных данных до подготовки витрин.
- **Воспроизводимость и изоляция**: весь стек контейнеризован, что гарантирует стабильность среды на разных этапах разработки и развертывания.
- **Масштабируемость**: архитектура предусматривает лёгкое добавление новых источников, моделей трансформации и конечных систем-потребителей.
- **Гибкость хранилища**: данные хранятся в формате Parquet, пригодном для анализа как SQL-движками, так и Data Science-инструментами.
- **Облачная совместимость**: финальные данные направляются в AWS, что упрощает интеграцию с BI, архивацию, или подключение downstream-сервисов.
- **Разделение логики и исполнения**: оркестрация, трансформация и хранение развязаны и управляются независимо.

##3. Слои данных

| Слой   | Назначение                        | Формат       | Где храним            |
|--------|-----------------------------------|--------------|------------------------|
| Bronze | Сырые данные (csv, json, API)     | .csv / .json | Локально / MinIO       |
| Silver | Очищенные, нормализованные данные | .parquet     | Локально / MinIO       |
| Gold   | Агрегаты, витрины, отчёты         | .parquet     | Выгрузка на AWS S3     |

##4. Технологии и стек

### Оркестрация:
- **Airflow** (Docker)

### Ингест:
- Python (requests, pandas)

### Хранилище:
- Bronze/Silver: локально (data/) или через **MinIO**
- Gold: **AWS S3** (реальный аккаунт через boto3/S3Hook)

### Формат:
- **Parquet** (в silver/gold)
- CSV / JSON (bronze)

### Трансформация:
- Pandas / PyArrow (bronze → silver)
- **dbt + DuckDB** (silver → gold)

### Докеризация и запуск:
- Все компоненты упакованы в Docker
- Возможен деплой в Kubernetes (в следующих фазах)

## 5. Архитектура 1-й фазы

1. Источник (CSV/API) → сохраняется в `data/bronze/`
2. DAG запускает трансформацию → `data/silver/` (Parquet)
3. DAG запускает dbt → формируются витрины `data/gold/`
4. DAG выгружает gold на AWS S3

Все слои хранятся послойно в отдельных директориях. Управление пайплайном через Airflow DAG'и. Трансформации отделены логически (dbt-модели).

## 6. Перспективы расширения
- Добавление Kubernetes как среды запуска
- Проверка качества данных (Great Expectations)
- CDC-интеграция через Debezium + Kafka
- Параллельный запуск Dagster для сравнения
- Подключение BI-инструментов к gold (через PostgreSQL / S3 Athena)
- CI/CD пайплайны и auto-deploy DAG’ов и моделей

## 7. Открытые вопросы и компромиссы
- MinIO или просто файловая система для bronze/silver (в разработке — локально)
- PostgreSQL пока не используется — можно добавить на gold
- DuckDB vs. Parquet SQL (Athena) — выбрано DuckDB для простоты

## 8. Развёртывание и окружение
- Проект разворачивается через `docker-compose`
- Используется AWS CLI и boto3 для выгрузки
- Креденшелы AWS хранятся локально в `~/.aws/credentials`
- Возможна миграция в Kubernetes (через Helm / k8s-манифесты)
- AWS ключи хранятся вне кода: через `.aws/credentials` или переменные окружения
- Используются Airflow Connections для безопасной передачи конфигураций
- Для предотвращения утечки данных в git предусмотрены `.gitignore`, `.env` и инструкции по работе с конфиденциальной информацией

## 9. Возможные сценарии использования
Разработанное ядро может быть адаптировано для обработки различных типов данных — от информации о вакансиях, погоде и фильмах до транзакционных потоков и логов.
Например, при интеграции с API вакансий фреймворк позволяет построить витрины по рынкам труда, востребованным навыкам и динамике зарплат.

## 10. Поддержка и эксплуатация

Для обеспечения надёжности и устойчивости пайплайнов предусмотрены следующие подходы:

- Использование `airflow dags test` и unit-тестов ключевых функций трансформации
- Проверки dbt-моделей с помощью встроенных `dbt tests` (на null, уникальность, референциальную целостность)
- Возможность интеграции мониторинга (CloudWatch, Prometheus, Telegram-уведомления)
- Использование SLA в Airflow и автоматических retries для задач

В будущем возможно добавление кастомных сенсоров и алертов для продакшен-сценариев.
